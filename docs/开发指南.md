# è±†ç“£ä¹¦å•åŒæ­¥ä¸ Calibre é›†æˆè‡ªåŠ¨åŒ– - å¼€å‘æŒ‡å—

## å¼€å‘ç¯å¢ƒæ­å»º

### ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**ï¼šWindows 10/11ã€macOS æˆ– Linux
- **Python ç‰ˆæœ¬**ï¼š3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
- **Calibre**ï¼š5.0 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼Œå¹¶å¯ç”¨ Content Server
- **æ•°æ®åº“**ï¼šSQLiteï¼ˆå¼€å‘ç¯å¢ƒï¼‰/ PostgreSQLï¼ˆå¯é€‰ï¼Œç”Ÿäº§ç¯å¢ƒï¼‰
- **IDE**ï¼šæ¨è VSCode æˆ– PyCharm

### ç¯å¢ƒå‡†å¤‡

1. **å…‹éš†é¡¹ç›®**

   ```bash
   git clone <repository-url>
   cd è±†ç“£zlib
   ```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**

   ```bash
   # ä½¿ç”¨ venv
   python -m venv venv
   
   # æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
   # Windows
   venv\Scripts\activate
   # macOS/Linux
   source venv/bin/activate
   ```

3. **å®‰è£…ä¾èµ–**

   ```bash
   pip install -r requirements.txt
   ```

4. **é…ç½®æ–‡ä»¶è®¾ç½®**

   å¤åˆ¶ `config.yaml.example` åˆ° `config.yaml`ï¼Œå¹¶å¡«å†™ç›¸å…³é…ç½®ï¼š

   ```bash
   cp config.yaml.example config.yaml
   # ç¼–è¾‘ config.yaml å¡«å†™é…ç½®ä¿¡æ¯
   ```

5. **åˆå§‹åŒ–æ•°æ®åº“**

   ```bash
   # ä½¿ç”¨é¡¹ç›®æä¾›çš„åˆå§‹åŒ–è„šæœ¬
   python -c "from db.database import Database; db = Database('sqlite:///data/douban_books.db'); db.init_db()"
   ```

6. **å¯åŠ¨ Calibre Content Server**

   ```bash
   # å¯åŠ¨ Calibre Content Serverï¼Œæ›¿æ¢è·¯å¾„ä¸ºä½ çš„ä¹¦åº“è·¯å¾„
   calibre-server --port=8080 --username=your_username --password=your_password /path/to/your/calibre/library
   ```

## é¡¹ç›®ç»“æ„è¯´æ˜

é¡¹ç›®é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œå„æ¨¡å—èŒè´£æ˜ç¡®ï¼Œä¾¿äºå¼€å‘å’Œç»´æŠ¤ï¼š

```
è±†ç“£zlib/
â”œâ”€â”€ config/           # é…ç½®ç®¡ç†
â”œâ”€â”€ data/             # æ•°æ®å­˜å‚¨
â”œâ”€â”€ db/               # æ•°æ®åº“æ¨¡å‹å’Œæ“ä½œ
â”œâ”€â”€ scrapers/         # çˆ¬è™«æ¨¡å—
â”œâ”€â”€ services/         # æœåŠ¡æ¨¡å—
â”œâ”€â”€ scheduler/        # è°ƒåº¦ç³»ç»Ÿ
â”œâ”€â”€ utils/            # å·¥å…·å‡½æ•°
â”œâ”€â”€ tests/            # æµ‹è¯•ä»£ç 
â”œâ”€â”€ logs/             # æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ migrations/       # æ•°æ®åº“è¿ç§»è„šæœ¬
â”œâ”€â”€ main.py           # ä¸»ç¨‹åºå…¥å£
â””â”€â”€ config.yaml       # é…ç½®æ–‡ä»¶
```

## å¼€å‘è§„èŒƒ

### ä»£ç é£æ ¼

é¡¹ç›®éµå¾ª [PEP 8](https://www.python.org/dev/peps/pep-0008/) ç¼–ç è§„èŒƒï¼Œä½¿ç”¨ flake8 å’Œ pylint è¿›è¡Œä»£ç è´¨é‡æ£€æŸ¥ï¼š

```bash
# å®‰è£…ä»£ç æ£€æŸ¥å·¥å…·
pip install flake8 pylint

# è¿è¡Œæ£€æŸ¥
flake8 .
pylint --recursive=y .
```

ä¸»è¦è§„èŒƒè¦ç‚¹ï¼š

1. **å‘½åè§„èŒƒ**
   - ç±»åï¼šä½¿ç”¨ CamelCaseï¼ˆå¦‚ `DoubanScraper`ï¼‰
   - å‡½æ•°å’Œå˜é‡ï¼šä½¿ç”¨ snake_caseï¼ˆå¦‚ `get_book_info`ï¼‰
   - å¸¸é‡ï¼šä½¿ç”¨å…¨å¤§å†™ SNAKE_CASEï¼ˆå¦‚ `MAX_RETRY_COUNT`ï¼‰

2. **æ–‡æ¡£æ³¨é‡Š**
   - æ‰€æœ‰æ¨¡å—ã€ç±»å’Œå‡½æ•°éƒ½åº”æœ‰æ–‡æ¡£å­—ç¬¦ä¸²
   - ä½¿ç”¨ Google é£æ ¼çš„æ–‡æ¡£æ³¨é‡Š

   ```python
   def function_name(param1, param2):
       """å‡½æ•°ç®€çŸ­æè¿°ã€‚
       
       è¯¦ç»†æè¿°ï¼ˆå¯é€‰ï¼‰ã€‚
       
       Args:
           param1: å‚æ•°1çš„æè¿°
           param2: å‚æ•°2çš„æè¿°
           
       Returns:
           è¿”å›å€¼æè¿°
           
       Raises:
           ExceptionType: å¼‚å¸¸æƒ…å†µæè¿°
       """
       # å‡½æ•°å®ç°
   ```

3. **å¯¼å…¥é¡ºåº**
   - æ ‡å‡†åº“å¯¼å…¥
   - ç›¸å…³ç¬¬ä¸‰æ–¹å¯¼å…¥
   - æœ¬åœ°åº”ç”¨/åº“ç‰¹å®šå¯¼å…¥

   ```python
   # æ ‡å‡†åº“
   import os
   import sys
   from datetime import datetime
   
   # ç¬¬ä¸‰æ–¹åº“
   import requests
   from bs4 import BeautifulSoup
   
   # æœ¬åœ°æ¨¡å—
   from db.models import DoubanBook
   from utils.logger import get_logger
   ```

4. **é”™è¯¯å¤„ç†**
   - ä½¿ç”¨æ˜ç¡®çš„å¼‚å¸¸ç±»å‹
   - æä¾›æœ‰æ„ä¹‰çš„é”™è¯¯æ¶ˆæ¯
   - é€‚å½“è®°å½•å¼‚å¸¸ä¿¡æ¯

   ```python
   try:
       # å¯èƒ½å¼•å‘å¼‚å¸¸çš„ä»£ç 
   except RequestException as e:
       logger.error(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
       raise ConnectionError(f"æ— æ³•è¿æ¥åˆ°è±†ç“£: {e}") from e
   ```

### æ—¥å¿—è§„èŒƒ

ä½¿ç”¨é¡¹ç›®æä¾›çš„æ—¥å¿—å·¥å…·ï¼Œç¡®ä¿æ—¥å¿—ä¿¡æ¯æ¸…æ™°æœ‰ç”¨ï¼š

```python
from utils.logger import get_logger

logger = get_logger(__name__)

# ä½¿ç”¨ä¸åŒçº§åˆ«çš„æ—¥å¿—
logger.debug("è¯¦ç»†è°ƒè¯•ä¿¡æ¯")
logger.info("ä¸€èˆ¬ä¿¡æ¯")
logger.warning("è­¦å‘Šä¿¡æ¯")
logger.error("é”™è¯¯ä¿¡æ¯")
logger.critical("ä¸¥é‡é”™è¯¯ä¿¡æ¯")
```

### æµ‹è¯•è§„èŒƒ

é¡¹ç›®ä½¿ç”¨ pytest è¿›è¡Œæµ‹è¯•ï¼Œæµ‹è¯•æ–‡ä»¶åº”æ”¾åœ¨ `tests/` ç›®å½•ä¸‹ï¼š

```python
# tests/test_douban_scraper.py
import pytest
from scrapers.douban_scraper import DoubanScraper

def test_parse_book_info():
    # æµ‹è¯•ä»£ç 
    scraper = DoubanScraper("test_cookie")
    html = "<html>æµ‹è¯•HTML</html>"
    result = scraper.parse_book_info(html)
    assert "title" in result
    assert "author" in result
```

è¿è¡Œæµ‹è¯•ï¼š

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
pytest tests/test_douban_scraper.py

# å¸¦è¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=. tests/
```

## æ¨¡å—å¼€å‘æŒ‡å—

### 1. é…ç½®ç®¡ç†æ¨¡å—

**æ–‡ä»¶**ï¼š`config/config_manager.py`

**èŒè´£**ï¼šåŠ è½½å’ŒéªŒè¯é…ç½®æ–‡ä»¶ï¼Œæä¾›é…ç½®è®¿é—®æ¥å£ã€‚

**å®ç°è¦ç‚¹**ï¼š
- ä½¿ç”¨ PyYAML è§£æ YAML é…ç½®æ–‡ä»¶
- å®ç°é…ç½®éªŒè¯é€»è¾‘ï¼Œç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
- æä¾›è·å–å„æ¨¡å—é…ç½®çš„æ–¹æ³•

**ç¤ºä¾‹ä»£ç **ï¼š

```python
import yaml
from pathlib import Path

class ConfigManager:
    def __init__(self, config_path):
        self.config_path = Path(config_path)
        self.config = self._load_config()
        self._validate_config()
    
    def _load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶ã€‚"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            raise ValueError(f"æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶: {e}") from e
    
    def _validate_config(self):
        """éªŒè¯é…ç½®æ–‡ä»¶ã€‚"""
        required_sections = ['douban', 'database', 'calibre', 'zlibrary', 'schedule', 'lark']
        for section in required_sections:
            if section not in self.config:
                raise ValueError(f"é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„ '{section}' éƒ¨åˆ†")
        
        # éªŒè¯å„éƒ¨åˆ†çš„å¿…è¦å­—æ®µ
        if 'cookie' not in self.config['douban']:
            raise ValueError("é…ç½®æ–‡ä»¶ç¼ºå°‘ 'douban.cookie' å­—æ®µ")
        # å…¶ä»–éªŒè¯...
    
    def get_douban_config(self):
        """è·å–è±†ç“£ç›¸å…³é…ç½®ã€‚"""
        return self.config['douban']
    
    def get_database_url(self):
        """è·å–æ•°æ®åº“è¿æ¥ URLã€‚"""
        db_config = self.config['database']
        if db_config['type'] == 'sqlite':
            return f"sqlite:///{db_config['path']}"
        elif db_config['type'] == 'postgresql':
            return f"postgresql://{db_config['username']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}"
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®åº“ç±»å‹: {db_config['type']}")
    
    # å…¶ä»–é…ç½®è·å–æ–¹æ³•...
```

### 2. æ•°æ®åº“æ¨¡å—

**æ–‡ä»¶**ï¼š`db/models.py` å’Œ `db/database.py`

**èŒè´£**ï¼šå®šä¹‰æ•°æ®æ¨¡å‹ï¼Œæä¾›æ•°æ®åº“æ“ä½œæ¥å£ã€‚

**å®ç°è¦ç‚¹**ï¼š
- ä½¿ç”¨ SQLAlchemy ORM å®šä¹‰æ•°æ®æ¨¡å‹
- å®ç°æ•°æ®åº“è¿æ¥å’Œä¼šè¯ç®¡ç†
- æä¾› CRUD æ“ä½œæ¥å£

**ç¤ºä¾‹ä»£ç **ï¼š

```python
# db/models.py
from sqlalchemy import Column, Integer, String, DateTime, Text
from sqlalchemy.ext.declarative import declarative_base
from datetime import datetime

Base = declarative_base()

class DoubanBook(Base):
    """è±†ç“£ä¹¦ç±æ•°æ®æ¨¡å‹ã€‚"""
    __tablename__ = 'douban_books'
    
    id = Column(Integer, primary_key=True)
    title = Column(String(255), nullable=False)
    author = Column(String(255))
    douban_url = Column(String(255), unique=True)
    status = Column(String(50))  # new/matched/downloaded/uploaded
    created_at = Column(DateTime, default=datetime.now)
    
    def __repr__(self):
        return f"<DoubanBook(title='{self.title}', author='{self.author}')>"

# db/database.py
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, scoped_session
from contextlib import contextmanager
from .models import Base, DoubanBook
from utils.logger import get_logger

logger = get_logger(__name__)

class Database:
    def __init__(self, db_url):
        self.engine = create_engine(db_url)
        self.Session = scoped_session(sessionmaker(bind=self.engine))
    
    def init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“ã€‚"""
        logger.info("åˆå§‹åŒ–æ•°æ®åº“...")
        Base.metadata.create_all(self.engine)
        logger.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
    
    @contextmanager
    def session_scope(self):
        """æä¾›äº‹åŠ¡ä¼šè¯ä¸Šä¸‹æ–‡ã€‚"""
        session = self.Session()
        try:
            yield session
            session.commit()
        except Exception as e:
            session.rollback()
            logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
            raise
        finally:
            session.close()
    
    def add_book(self, title, author, douban_url):
        """æ·»åŠ ä¹¦ç±è®°å½•ã€‚"""
        with self.session_scope() as session:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing = session.query(DoubanBook).filter_by(douban_url=douban_url).first()
            if existing:
                logger.info(f"ä¹¦ç±å·²å­˜åœ¨: {title}")
                return existing
            
            # åˆ›å»ºæ–°è®°å½•
            book = DoubanBook(
                title=title,
                author=author,
                douban_url=douban_url,
                status="new"
            )
            session.add(book)
            logger.info(f"æ·»åŠ æ–°ä¹¦ç±: {title}")
            return book
    
    def update_book_status(self, book_id, status):
        """æ›´æ–°ä¹¦ç±çŠ¶æ€ã€‚"""
        with self.session_scope() as session:
            book = session.query(DoubanBook).filter_by(id=book_id).first()
            if not book:
                logger.warning(f"æœªæ‰¾åˆ°ä¹¦ç± ID: {book_id}")
                return False
            
            book.status = status
            logger.info(f"æ›´æ–°ä¹¦ç±çŠ¶æ€: {book.title} -> {status}")
            return True
    
    def get_books_by_status(self, status):
        """è·å–æŒ‡å®šçŠ¶æ€çš„ä¹¦ç±ã€‚"""
        with self.session_scope() as session:
            books = session.query(DoubanBook).filter_by(status=status).all()
            return books
    
    # å…¶ä»–æ•°æ®åº“æ“ä½œæ–¹æ³•...
```

### 3. è±†ç“£çˆ¬è™«æ¨¡å—

**æ–‡ä»¶**ï¼š`scrapers/douban_scraper.py`

**èŒè´£**ï¼šçˆ¬å–è±†ç“£ã€Œæƒ³è¯»ã€ä¹¦å•ï¼Œè§£æä¹¦ç±ä¿¡æ¯ã€‚

**å®ç°è¦ç‚¹**ï¼š
- ä½¿ç”¨ requests å’Œ BeautifulSoup è¿›è¡Œç½‘é¡µçˆ¬å–å’Œè§£æ
- å¤„ç†åˆ†é¡µå’Œå¼‚å¸¸æƒ…å†µ
- å®ç°é‡è¯•æœºåˆ¶

**ç¤ºä¾‹ä»£ç **ï¼š

```python
import requests
from bs4 import BeautifulSoup
import time
from requests.exceptions import RequestException
from utils.logger import get_logger

logger = get_logger(__name__)

class DoubanScraper:
    def __init__(self, cookie):
        self.cookie = cookie
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Cookie': cookie
        }
        self.base_url = "https://book.douban.com/people/me/wish"
        self.max_retries = 3
        self.retry_delay = 2  # ç§’
    
    def _make_request(self, url):
        """å‘é€ HTTP è¯·æ±‚ï¼Œå¸¦é‡è¯•æœºåˆ¶ã€‚"""
        for attempt in range(self.max_retries):
            try:
                response = requests.get(url, headers=self.headers, timeout=10)
                response.raise_for_status()
                return response
            except RequestException as e:
                logger.warning(f"è¯·æ±‚å¤±è´¥ (å°è¯• {attempt+1}/{self.max_retries}): {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                else:
                    logger.error(f"è¯·æ±‚å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {url}")
                    raise
    
    def get_wish_list(self):
        """è·å–ã€Œæƒ³è¯»ã€ä¹¦å•ã€‚"""
        all_books = []
        page = 0
        has_next = True
        
        while has_next:
            page += 1
            url = f"{self.base_url}?start={(page-1)*15}&sort=time&rating=all&filter=all&mode=grid"
            logger.info(f"çˆ¬å–ç¬¬ {page} é¡µ: {url}")
            
            try:
                response = self._make_request(url)
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # è§£æä¹¦ç±åˆ—è¡¨
                book_items = soup.select('.subject-item')
                if not book_items:
                    logger.warning(f"ç¬¬ {page} é¡µæœªæ‰¾åˆ°ä¹¦ç±ï¼Œå¯èƒ½æ˜¯é¡µé¢ç»“æ„å˜åŒ–æˆ–å·²åˆ°è¾¾æœ«é¡µ")
                    break
                
                for item in book_items:
                    book_info = self.parse_book_info(item)
                    if book_info:
                        all_books.append(book_info)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
                next_link = soup.select_one('.paginator .next a')
                has_next = next_link is not None
                
                # é˜²æ­¢è¯·æ±‚è¿‡å¿«
                time.sleep(1)
                
            except Exception as e:
                logger.error(f"çˆ¬å–ç¬¬ {page} é¡µæ—¶å‡ºé”™: {e}")
                break
        
        logger.info(f"å…±çˆ¬å– {len(all_books)} æœ¬ä¹¦")
        return all_books
    
    def parse_book_info(self, item):
        """è§£æä¹¦ç±ä¿¡æ¯ã€‚"""
        try:
            # æå–ä¹¦å
            title_elem = item.select_one('.title a')
            if not title_elem:
                return None
            
            title = title_elem.text.strip()
            douban_url = title_elem['href']
            
            # æå–ä½œè€…
            pub_info = item.select_one('.pub')
            author = "æœªçŸ¥"
            if pub_info:
                pub_text = pub_info.text.strip()
                parts = pub_text.split('/')
                if len(parts) > 0:
                    author = parts[0].strip()
            
            return {
                'title': title,
                'author': author,
                'douban_url': douban_url
            }
        except Exception as e:
            logger.error(f"è§£æä¹¦ç±ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def run(self):
        """æ‰§è¡Œçˆ¬è™«ä»»åŠ¡ã€‚"""
        logger.info("å¼€å§‹çˆ¬å–è±†ç“£ã€Œæƒ³è¯»ã€ä¹¦å•")
        try:
            books = self.get_wish_list()
            logger.info(f"çˆ¬å–å®Œæˆï¼Œå…±è·å– {len(books)} æœ¬ä¹¦")
            return books
        except Exception as e:
            logger.error(f"çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            raise
```

### 4. Calibre æŸ¥è¯¢æ¨¡å—

**æ–‡ä»¶**ï¼š`services/calibre_service.py`

**èŒè´£**ï¼šæŸ¥è¯¢ Calibre ä¹¦åº“ï¼Œåˆ¤æ–­ä¹¦ç±æ˜¯å¦å·²æ”¶å½•ã€‚

**å®ç°è¦ç‚¹**ï¼š
- è°ƒç”¨ Calibre Content Server API
- å®ç°æ¨¡ç³ŠåŒ¹é…ç®—æ³•
- å¤„ç†è®¤è¯å’Œå¼‚å¸¸æƒ…å†µ

**ç¤ºä¾‹ä»£ç **ï¼š

```python
import requests
from requests.auth import HTTPBasicAuth
import re
from difflib import SequenceMatcher
from utils.logger import get_logger

logger = get_logger(__name__)

class CalibreService:
    def __init__(self, server_url, username, password):
        self.server_url = server_url.rstrip('/')
        self.username = username
        self.password = password
        self.auth = HTTPBasicAuth(username, password)
        self.session = requests.Session()
    
    def _make_request(self, endpoint, method='get', **kwargs):
        """å‘é€è¯·æ±‚åˆ° Calibre Content Serverã€‚"""
        url = f"{self.server_url}/{endpoint}"
        try:
            if method.lower() == 'get':
                response = self.session.get(url, auth=self.auth, **kwargs)
            elif method.lower() == 'post':
                response = self.session.post(url, auth=self.auth, **kwargs)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„ HTTP æ–¹æ³•: {method}")
            
            response.raise_for_status()
            return response
        except requests.exceptions.RequestException as e:
            logger.error(f"Calibre æœåŠ¡å™¨è¯·æ±‚å¤±è´¥: {e}")
            raise
    
    def search_book(self, title, author):
        """æœç´¢ä¹¦ç±ã€‚"""
        logger.info(f"åœ¨ Calibre ä¸­æœç´¢: {title} - {author}")
        
        # æ„å»ºæœç´¢æŸ¥è¯¢
        # å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
        query = f"title:~\"{title}\" author:~\"{author}\""
        try:
            response = self._make_request(f"ajax/search?query={query}")
            results = response.json()
            
            if results['total_num'] > 0:
                logger.info(f"æ‰¾åˆ°ç²¾ç¡®åŒ¹é…ç»“æœ: {results['total_num']} æœ¬")
                return results['book_ids']
            
            # å¦‚æœç²¾ç¡®åŒ¹é…æ²¡æœ‰ç»“æœï¼Œå°è¯•æ›´å®½æ¾çš„æœç´¢
            logger.info("ç²¾ç¡®åŒ¹é…æœªæ‰¾åˆ°ç»“æœï¼Œå°è¯•æ¨¡ç³Šæœç´¢")
            title_terms = re.sub(r'[^\w\s]', '', title).split()
            query = " or ".join([f"title:~\"{term}\"" for term in title_terms])
            
            if author:
                author_terms = re.sub(r'[^\w\s]', '', author).split()
                author_query = " or ".join([f"author:~\"{term}\"" for term in author_terms])
                query = f"({query}) and ({author_query})"
            
            response = self._make_request(f"ajax/search?query={query}")
            results = response.json()
            
            if results['total_num'] > 0:
                logger.info(f"æ‰¾åˆ°æ¨¡ç³ŠåŒ¹é…ç»“æœ: {results['total_num']} æœ¬")
                # è·å–å€™é€‰ä¹¦ç±çš„è¯¦ç»†ä¿¡æ¯
                candidates = []
                for book_id in results['book_ids']:
                    book_data = self._get_book_data(book_id)
                    if book_data:
                        candidates.append(book_data)
                
                # ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…æ‰¾å‡ºæœ€ä½³åŒ¹é…
                best_match = self._fuzzy_match(title, author, candidates)
                if best_match:
                    logger.info(f"æœ€ä½³åŒ¹é…: {best_match['title']} - {best_match['authors']}")
                    return [best_match['id']]
            
            logger.info("æœªæ‰¾åˆ°åŒ¹é…çš„ä¹¦ç±")
            return []
            
        except Exception as e:
            logger.error(f"æœç´¢ä¹¦ç±æ—¶å‡ºé”™: {e}")
            return []
    
    def _get_book_data(self, book_id):
        """è·å–ä¹¦ç±è¯¦ç»†ä¿¡æ¯ã€‚"""
        try:
            response = self._make_request(f"ajax/book/{book_id}")
            return response.json()
        except Exception as e:
            logger.error(f"è·å–ä¹¦ç±æ•°æ®å¤±è´¥ (ID: {book_id}): {e}")
            return None
    
    def _fuzzy_match(self, title, author, candidates):
        """æ¨¡ç³ŠåŒ¹é…ç®—æ³•ã€‚"""
        best_score = 0
        best_match = None
        
        for book in candidates:
            # è®¡ç®—æ ‡é¢˜ç›¸ä¼¼åº¦
            title_score = SequenceMatcher(None, title.lower(), book['title'].lower()).ratio()
            
            # è®¡ç®—ä½œè€…ç›¸ä¼¼åº¦
            author_score = 0
            if author and 'authors' in book and book['authors']:
                # å°è¯•ä¸åŒçš„ä½œè€…åæ ¼å¼ï¼ˆå§“åé¡ºåºå¯èƒ½ä¸åŒï¼‰
                author_variants = [author, ' '.join(reversed(author.split()))]
                for variant in author_variants:
                    for book_author in book['authors']:
                        score = SequenceMatcher(None, variant.lower(), book_author.lower()).ratio()
                        author_score = max(author_score, score)
            
            # ç»¼åˆè¯„åˆ†ï¼ˆæ ‡é¢˜æƒé‡æ›´é«˜ï¼‰
            combined_score = title_score * 0.7 + author_score * 0.3
            
            if combined_score > best_score:
                best_score = combined_score
                best_match = book
        
        # è®¾ç½®åŒ¹é…é˜ˆå€¼
        if best_score >= 0.6:
            return best_match
        return None
    
    def upload_book(self, file_path, metadata=None):
        """ä¸Šä¼ ä¹¦ç±åˆ° Calibreã€‚"""
        logger.info(f"ä¸Šä¼ ä¹¦ç±: {file_path}")
        try:
            with open(file_path, 'rb') as f:
                files = {'file': f}
                data = {}
                if metadata:
                    data['title'] = metadata.get('title', '')
                    data['authors'] = metadata.get('author', '')
                
                response = self._make_request('cdb/add-book', method='post', files=files, data=data)
                result = response.json()
                
                if 'book_id' in result:
                    logger.info(f"ä¸Šä¼ æˆåŠŸï¼Œä¹¦ç± ID: {result['book_id']}")
                    return result['book_id']
                else:
                    logger.error(f"ä¸Šä¼ å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    return None
        except Exception as e:
            logger.error(f"ä¸Šä¼ ä¹¦ç±æ—¶å‡ºé”™: {e}")
            return None
```

### 5. Z-Library ä¸‹è½½æ¨¡å—

**æ–‡ä»¶**ï¼š`services/zlibrary_service.py`

**èŒè´£**ï¼šä» Z-Library æœç´¢å’Œä¸‹è½½ä¹¦ç±ã€‚

**å®ç°è¦ç‚¹**ï¼š
- ä½¿ç”¨ zlibrary åŒ…è¿›è¡Œ API è°ƒç”¨
- å®ç°æ ¼å¼ä¼˜å…ˆçº§é€‰æ‹©
- å¤„ç†ä¸‹è½½é™åˆ¶å’Œå¼‚å¸¸æƒ…å†µ

**ç¤ºä¾‹ä»£ç **ï¼š

```python
import os
import time
from pathlib import Path
from zlibrary import ZLibrary
from utils.logger import get_logger

logger = get_logger(__name__)

class ZLibraryService:
    def __init__(self, username, password, format_priority):
        self.username = username
        self.password = password
        self.format_priority = format_priority
        self.client = None
        self.max_retries = 3
        self.retry_delay = 5  # ç§’
    
    def _ensure_client(self):
        """ç¡®ä¿å®¢æˆ·ç«¯å·²åˆå§‹åŒ–å¹¶ç™»å½•ã€‚"""
        if self.client is None:
            logger.info(f"åˆå§‹åŒ– Z-Library å®¢æˆ·ç«¯å¹¶ç™»å½•: {self.username}")
            try:
                self.client = ZLibrary()
                self.client.login(self.username, self.password)
                logger.info("Z-Library ç™»å½•æˆåŠŸ")
            except Exception as e:
                logger.error(f"Z-Library ç™»å½•å¤±è´¥: {e}")
                raise
    
    def search_book(self, title, author):
        """æœç´¢ä¹¦ç±ã€‚"""
        self._ensure_client()
        search_query = f"{title} {author}".strip()
        logger.info(f"åœ¨ Z-Library æœç´¢: {search_query}")
        
        for attempt in range(self.max_retries):
            try:
                results = self.client.search(search_query)
                if not results:
                    logger.info(f"æœªæ‰¾åˆ°åŒ¹é…çš„ä¹¦ç±: {search_query}")
                    return None
                
                logger.info(f"æ‰¾åˆ° {len(results)} ä¸ªæœç´¢ç»“æœ")
                
                # é€‰æ‹©æœ€ä½³åŒ¹é…ç»“æœ
                best_match = self._select_best_match(results, title, author)
                if best_match:
                    logger.info(f"æœ€ä½³åŒ¹é…: {best_match['title']} - {best_match['author']}")
                    return best_match
                
                logger.info("æœªæ‰¾åˆ°åˆé€‚çš„åŒ¹é…")
                return None
                
            except Exception as e:
                logger.warning(f"æœç´¢å¤±è´¥ (å°è¯• {attempt+1}/{self.max_retries}): {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                else:
                    logger.error(f"æœç´¢å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                    raise
    
    def _select_best_match(self, results, title, author):
        """ä»æœç´¢ç»“æœä¸­é€‰æ‹©æœ€ä½³åŒ¹é…ã€‚"""
        # ç®€å•å®ç°ï¼šé€‰æ‹©ç¬¬ä¸€ä¸ªç»“æœ
        # å®é™…åº”ç”¨ä¸­åº”è¯¥å®ç°æ›´å¤æ‚çš„åŒ¹é…ç®—æ³•
        if results:
            return results[0]
        return None
    
    def download_book(self, book_id, output_dir):
        """ä¸‹è½½ä¹¦ç±ã€‚"""
        self._ensure_client()
        logger.info(f"å‡†å¤‡ä¸‹è½½ä¹¦ç± ID: {book_id}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        for attempt in range(self.max_retries):
            try:
                # è·å–ä¹¦ç±è¯¦æƒ…
                book_info = self.client.get_book(book_id)
                if not book_info:
                    logger.error(f"æ— æ³•è·å–ä¹¦ç±ä¿¡æ¯: {book_id}")
                    return None
                
                # é€‰æ‹©æœ€ä½³æ ¼å¼
                available_formats = book_info.get('formats', [])
                best_format = self.select_best_format(available_formats)
                if not best_format:
                    logger.warning(f"æœªæ‰¾åˆ°æ”¯æŒçš„æ ¼å¼: {available_formats}")
                    return None
                
                # ä¸‹è½½ä¹¦ç±
                logger.info(f"ä¸‹è½½æ ¼å¼: {best_format}")
                file_path = os.path.join(output_dir, f"{book_info['title']}.{best_format}".replace('/', '_'))
                
                success = self.client.download(book_id, file_path, format=best_format)
                if success:
                    logger.info(f"ä¸‹è½½æˆåŠŸ: {file_path}")
                    return file_path
                else:
                    logger.error("ä¸‹è½½å¤±è´¥")
                    return None
                
            except Exception as e:
                logger.warning(f"ä¸‹è½½å¤±è´¥ (å°è¯• {attempt+1}/{self.max_retries}): {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                else:
                    logger.error(f"ä¸‹è½½å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                    raise
    
    def select_best_format(self, available_formats):
        """æŒ‰ä¼˜å…ˆçº§é€‰æ‹©æœ€ä½³æ ¼å¼ã€‚"""
        for format_type in self.format_priority:
            if format_type.lower() in [f.lower() for f in available_formats]:
                return format_type.lower()
        return None
```

### 6. é£ä¹¦é€šçŸ¥æ¨¡å—

**æ–‡ä»¶**ï¼š`services/lark_service.py`

**èŒè´£**ï¼šé€šè¿‡é£ä¹¦æœºå™¨äººå‘é€é€šçŸ¥æ¶ˆæ¯ã€‚

**å®ç°è¦ç‚¹**ï¼š
- è°ƒç”¨é£ä¹¦ Webhook API
- æ ¼å¼åŒ–æ¶ˆæ¯å†…å®¹
- å¤„ç†å‘é€å¤±è´¥æƒ…å†µ

**ç¤ºä¾‹ä»£ç **ï¼š

```python
import requests
import json
from datetime import datetime
from utils.logger import get_logger

logger = get_logger(__name__)

class LarkService:
    def __init__(self, webhook_url):
        self.webhook_url = webhook_url
    
    def send_message(self, title, content):
        """å‘é€æ¶ˆæ¯åˆ°é£ä¹¦ã€‚"""
        logger.info(f"å‘é€é£ä¹¦æ¶ˆæ¯: {title}")
        
        message = {
            "msg_type": "post",
            "content": {
                "post": {
                    "zh_cn": {
                        "title": title,
                        "content": [
                            [
                                {"tag": "text", "text": content}
                            ]
                        ]
                    }
                }
            }
        }
        
        try:
            response = requests.post(
                self.webhook_url,
                headers={"Content-Type": "application/json"},
                data=json.dumps(message)
            )
            response.raise_for_status()
            
            result = response.json()
            if result.get('code') == 0:
                logger.info("é£ä¹¦æ¶ˆæ¯å‘é€æˆåŠŸ")
                return True
            else:
                logger.error(f"é£ä¹¦æ¶ˆæ¯å‘é€å¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                return False
                
        except Exception as e:
            logger.error(f"å‘é€é£ä¹¦æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            return False
    
    def format_task_report(self, stats):
        """æ ¼å¼åŒ–ä»»åŠ¡æŠ¥å‘Šã€‚"""
        today = datetime.now().strftime("%Y-%m-%d")
        report = f"ğŸ“š è±†ç“£ä¹¦å•åŒæ­¥ä»»åŠ¡å®Œæˆ\n\n"
        report += f"- æ–°å¢ä¹¦ç±ï¼š{stats.get('new', 0)} æœ¬\n"
        report += f"- å·²å­˜åœ¨ä¹¦ç±ï¼š{stats.get('matched', 0)} æœ¬\n"
        report += f"- æˆåŠŸä¸‹è½½å¹¶ä¸Šä¼ ï¼š{stats.get('uploaded', 0)} æœ¬\n"
        report += f"- ä¸‹è½½å¤±è´¥ï¼š{stats.get('failed', 0)} æœ¬\n\n"
        report += f"è¯¦ç»†æ—¥å¿—è¯·è§æœ¬åœ°æ–‡ä»¶ logs/task_{today}.log"
        
        return report
    
    def send_task_report(self, stats):
        """å‘é€ä»»åŠ¡æŠ¥å‘Šã€‚"""
        title = "ğŸ“š è±†ç“£ä¹¦å•åŒæ­¥ä»»åŠ¡å®Œæˆ"
        content = self.format_task_report(stats)
        return self.send_message(title, content)
```

### 7. è°ƒåº¦ç³»ç»Ÿ

**æ–‡ä»¶**ï¼š`scheduler/task_scheduler.py`

**èŒè´£**ï¼šç®¡ç†å®šæ—¶ä»»åŠ¡ï¼Œåè°ƒå„æ¨¡å—å·¥ä½œã€‚

**å®ç°è¦ç‚¹**ï¼š
- ä½¿ç”¨ APScheduler å®ç°å®šæ—¶è°ƒåº¦
- å®ç°ä»»åŠ¡æ‰§è¡Œé€»è¾‘
- å¤„ç†ä»»åŠ¡å¤±è´¥å’Œæ¢å¤

**ç¤ºä¾‹ä»£ç **ï¼š

```python
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
import tempfile
import shutil
from datetime import datetime
from utils.logger import get_logger

logger = get_logger(__name__)

class TaskScheduler:
    def __init__(self, config_manager, db, douban_scraper, calibre_service, zlibrary_service, lark_service):
        self.scheduler = BackgroundScheduler()
        self.config = config_manager
        self.db = db
        self.douban_scraper = douban_scraper
        self.calibre_service = calibre_service
        self.zlibrary_service = zlibrary_service
        self.lark_service = lark_service
        self.temp_dir = tempfile.mkdtemp(prefix="douban_zlib_")
        self.stats = {
            'new': 0,
            'matched': 0,
            'uploaded': 0,
            'failed': 0
        }
    
    def setup_jobs(self):
        """è®¾ç½®å®šæ—¶ä»»åŠ¡ã€‚"""
        schedule_time = self.config.config['schedule']['time']
        hour, minute = schedule_time.split(':')
        
        # æ·»åŠ æ¯æ—¥åŒæ­¥ä»»åŠ¡
        self.scheduler.add_job(
            self.run_sync_task,
            CronTrigger(hour=hour, minute=minute),
            id='daily_sync',
            replace_existing=True
        )
        
        logger.info(f"å·²è®¾ç½®æ¯æ—¥åŒæ­¥ä»»åŠ¡ï¼Œæ‰§è¡Œæ—¶é—´: {schedule_time}")
    
    def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨ã€‚"""
        self.scheduler.start()
        logger.info("è°ƒåº¦å™¨å·²å¯åŠ¨")
    
    def stop(self):
        """åœæ­¢è°ƒåº¦å™¨ã€‚"""
        self.scheduler.shutdown()
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        try:
            shutil.rmtree(self.temp_dir)
        except Exception as e:
            logger.warning(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
        logger.info("è°ƒåº¦å™¨å·²åœæ­¢")
    
    def run_sync_task(self):
        """æ‰§è¡ŒåŒæ­¥ä»»åŠ¡ã€‚"""
        logger.info("å¼€å§‹æ‰§è¡ŒåŒæ­¥ä»»åŠ¡")
        start_time = datetime.now()
        
        # é‡ç½®ç»Ÿè®¡æ•°æ®
        self.stats = {'new': 0, 'matched': 0, 'uploaded': 0, 'failed': 0}
        
        try:
            # 1. çˆ¬å–è±†ç“£ä¹¦å•
            books = self.douban_scraper.run()
            
            # 2. å¤„ç†æ¯æœ¬ä¹¦
            for book in books:
                self._process_book(book)
            
            # 3. å‘é€ä»»åŠ¡æŠ¥å‘Š
            self.lark_service.send_task_report(self.stats)
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds() / 60
            logger.info(f"åŒæ­¥ä»»åŠ¡å®Œæˆï¼Œè€—æ—¶: {duration:.2f} åˆ†é’Ÿ")
            
        except Exception as e:
            logger.error(f"åŒæ­¥ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            # å°è¯•å‘é€é”™è¯¯æŠ¥å‘Š
            self.lark_service.send_message(
                "âŒ è±†ç“£ä¹¦å•åŒæ­¥ä»»åŠ¡å¤±è´¥",
                f"åŒæ­¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}\n\nè¯·æ£€æŸ¥æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚"
            )
    
    def _process_book(self, book):
        """å¤„ç†å•æœ¬ä¹¦ç±ã€‚"""
        title = book['title']
        author = book['author']
        douban_url = book['douban_url']
        
        logger.info(f"å¤„ç†ä¹¦ç±: {title} - {author}")
        
        # 1. æ·»åŠ åˆ°æ•°æ®åº“
        db_book = self.db.add_book(title, author, douban_url)
        if db_book.status != 'new':
            logger.info(f"ä¹¦ç±å·²å­˜åœ¨äºæ•°æ®åº“: {title}")
            return
        
        self.stats['new'] += 1
        
        # 2. æŸ¥è¯¢ Calibre æ˜¯å¦å·²æœ‰æ­¤ä¹¦
        book_ids = self.calibre_service.search_book(title, author)
        if book_ids:
            logger.info(f"ä¹¦ç±å·²å­˜åœ¨äº Calibre: {title}")
            self.db.update_book_status(db_book.id, 'matched')
            self.stats['matched'] += 1
            return
        
        # 3. ä» Z-Library ä¸‹è½½
        try:
            search_result = self.zlibrary_service.search_book(title, author)
            if not search_result:
                logger.warning(f"åœ¨ Z-Library ä¸­æœªæ‰¾åˆ°ä¹¦ç±: {title}")
                self.stats['failed'] += 1
                return
            
            book_id = search_result['id']
            file_path = self.zlibrary_service.download_book(book_id, self.temp_dir)
            if not file_path:
                logger.error(f"ä¸‹è½½ä¹¦ç±å¤±è´¥: {title}")
                self.db.update_book_status(db_book.id, 'download_failed')
                self.stats['failed'] += 1
                return
            
            self.db.update_book_status(db_book.id, 'downloaded')
            
            # 4. ä¸Šä¼ åˆ° Calibre
            metadata = {'title': title, 'author': author}
            calibre_id = self.calibre_service.upload_book(file_path, metadata)
            if calibre_id:
                logger.info(f"ä¹¦ç±å·²ä¸Šä¼ åˆ° Calibre: {title}")
                self.db.update_book_status(db_book.id, 'uploaded')
                self.stats['uploaded'] += 1
            else:
                logger.error(f"ä¸Šä¼ ä¹¦ç±åˆ° Calibre å¤±è´¥: {title}")
                self.stats['failed'] += 1
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                if file_path and os.path.exists(file_path):
                    os.remove(file_path)
            except Exception as e:
                logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
                
        except Exception as e:
            logger.error(f"å¤„ç†ä¹¦ç±æ—¶å‡ºé”™: {title} - {e}")
            self.stats['failed'] += 1
```

### 8. ä¸»ç¨‹åº

**æ–‡ä»¶**ï¼š`main.py`

**èŒè´£**ï¼šåˆå§‹åŒ–å’Œå¯åŠ¨ç³»ç»Ÿã€‚

**å®ç°è¦ç‚¹**ï¼š
- è§£æå‘½ä»¤è¡Œå‚æ•°
- åˆå§‹åŒ–å„æ¨¡å—
- å¯åŠ¨è°ƒåº¦ç³»ç»Ÿ

**ç¤ºä¾‹ä»£ç **ï¼š

```python
import argparse
import signal
import sys
from pathlib import Path

from config.config_manager import ConfigManager
from db.database import Database
from scrapers.douban_scraper import DoubanScraper
from services.calibre_service import CalibreService
from services.zlibrary_service import ZLibraryService
from services.lark_service import LarkService
from scheduler.task_scheduler import TaskScheduler
from utils.logger import setup_logger, get_logger

def signal_handler(sig, frame):
    """å¤„ç†ä¿¡å·ï¼Œä¼˜é›…é€€å‡ºã€‚"""
    logger = get_logger(__name__)
    logger.info("æ¥æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨åœæ­¢...")
    if 'scheduler' in globals():
        scheduler.stop()
    sys.exit(0)

def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='è±†ç“£ä¹¦å•åŒæ­¥ä¸ Calibre é›†æˆè‡ªåŠ¨åŒ–')
    parser.add_argument('--config', default='config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--run-now', action='store_true', help='ç«‹å³æ‰§è¡ŒåŒæ­¥ä»»åŠ¡')
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logger()
    logger.info("åˆå§‹åŒ–ç³»ç»Ÿ...")
    
    try:
        # åˆå§‹åŒ–é…ç½®
        config_path = Path(args.config)
        if not config_path.exists():
            logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            sys.exit(1)
        
        config_manager = ConfigManager(config_path)
        
        # åˆå§‹åŒ–æ•°æ®åº“
        db = Database(config_manager.get_database_url())
        db.init_db()
        
        # åˆå§‹åŒ–æœåŠ¡
        douban_config = config_manager.get_douban_config()
        douban_scraper = DoubanScraper(douban_config['cookie'])
        
        calibre_config = config_manager.config['calibre']
        calibre_service = CalibreService(
            calibre_config['content_server_url'],
            calibre_config['username'],
            calibre_config['password']
        )
        
        zlibrary_config = config_manager.config['zlibrary']
        zlibrary_service = ZLibraryService(
            zlibrary_config['username'],
            zlibrary_config['password'],
            zlibrary_config['format_priority']
        )
        
        lark_config = config_manager.config['lark']
        lark_service = LarkService(lark_config['webhook_url'])
        
        # åˆå§‹åŒ–è°ƒåº¦å™¨
        global scheduler
        scheduler = TaskScheduler(
            config_manager,
            db,
            douban_scraper,
            calibre_service,
            zlibrary_service,
            lark_service
        )
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        
        # è®¾ç½®å®šæ—¶ä»»åŠ¡
        scheduler.setup_jobs()
        
        # å¯åŠ¨è°ƒåº¦å™¨
        scheduler.start()
        
        # å¦‚æœæŒ‡å®šäº†ç«‹å³æ‰§è¡Œï¼Œåˆ™è¿è¡ŒåŒæ­¥ä»»åŠ¡
        if args.run_now:
            logger.info("ç«‹å³æ‰§è¡ŒåŒæ­¥ä»»åŠ¡")
            scheduler.run_sync_task()
        
        logger.info("ç³»ç»Ÿå·²å¯åŠ¨ï¼ŒæŒ‰ Ctrl+C åœæ­¢")
        
        # ä¿æŒä¸»çº¿ç¨‹è¿è¡Œ
        while True:
            signal.pause()
            
    except KeyboardInterrupt:
        logger.info("æ¥æ”¶åˆ°ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨åœæ­¢...")
        if 'scheduler' in globals():
            scheduler.stop()
    except Exception as e:
        logger.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == '__main__':
    main()
```

## è°ƒè¯•ä¸æµ‹è¯•æŠ€å·§

### 1. å•å…ƒæµ‹è¯•

ä¸ºæ¯ä¸ªæ¨¡å—ç¼–å†™å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿åŸºæœ¬åŠŸèƒ½æ­£ç¡®ï¼š

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
pytest tests/test_douban_scraper.py

# å¸¦è¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=. tests/
```

### 2. æ¨¡å—ç‹¬ç«‹æµ‹è¯•

å¯ä»¥å•ç‹¬æµ‹è¯•å„ä¸ªæ¨¡å—ï¼Œä¾¿äºè°ƒè¯•ï¼š

```python
# æµ‹è¯•è±†ç“£çˆ¬è™«
from scrapers.douban_scraper import DoubanScraper

scraper = DoubanScraper("your_cookie")
books = scraper.run()
print(f"çˆ¬å–åˆ° {len(books)} æœ¬ä¹¦")
for book in books[:5]:  # æ‰“å°å‰ 5 æœ¬
    print(f"{book['title']} - {book['author']}")
```

### 3. æ—¥å¿—åˆ†æ

ä½¿ç”¨æ—¥å¿—åˆ†æå·¥å…·æŸ¥çœ‹è¿è¡Œæ—¥å¿—ï¼Œå®šä½é—®é¢˜ï¼š

```bash
# æŸ¥çœ‹æœ€è¿‘çš„é”™è¯¯æ—¥å¿—
grep ERROR logs/app.log | tail -n 20

# ç»Ÿè®¡å„ç±»æ—¥å¿—æ•°é‡
grep -c "INFO" logs/app.log
grep -c "WARNING" logs/app.log
grep -c "ERROR" logs/app.log
```

### 4. è°ƒè¯•æ¨¡å¼è¿è¡Œ

ä½¿ç”¨è°ƒè¯•æ¨¡å¼è¿è¡Œç¨‹åºï¼Œä¾¿äºæ’æŸ¥é—®é¢˜ï¼š

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡å¯ç”¨è°ƒè¯•æ—¥å¿—
export DEBUG=1
python main.py --run-now
```

## éƒ¨ç½²æŒ‡å—

### 1. ç³»ç»Ÿè¦æ±‚

- Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
- Calibre 5.0 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼Œå¹¶å¯ç”¨ Content Server
- ç¨³å®šçš„ç½‘ç»œè¿æ¥
- è¶³å¤Ÿçš„å­˜å‚¨ç©ºé—´ï¼ˆè§†ä¹¦åº“å¤§å°è€Œå®šï¼‰

### 2. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

1. **å‡†å¤‡ç¯å¢ƒ**

   ```bash
   # åˆ›å»ºé¡¹ç›®ç›®å½•
   mkdir -p /opt/douban_zlib
   cd /opt/douban_zlib
   
   # åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
   python3 -m venv venv
   source venv/bin/activate
   
   # å…‹éš†ä»£ç 
   git clone <repository-url> .
   
   # å®‰è£…ä¾èµ–
   pip install -r requirements.txt
   ```

2. **é…ç½®ç³»ç»Ÿ**

   ```bash
   # å¤åˆ¶å¹¶ç¼–è¾‘é…ç½®æ–‡ä»¶
   cp config.yaml.example config.yaml
   nano config.yaml  # ç¼–è¾‘é…ç½®æ–‡ä»¶
   
   # åˆå§‹åŒ–æ•°æ®åº“
   python -c "from db.database import Database; db = Database('sqlite:///data/douban_books.db'); db.init_db()"
   ```

3. **è®¾ç½®è‡ªåŠ¨å¯åŠ¨**

   **Linux (systemd)**:

   åˆ›å»ºæœåŠ¡æ–‡ä»¶ `/etc/systemd/system/douban-zlib.service`ï¼š

   ```ini
   [Unit]
   Description=Douban ZLibrary Sync Service
   After=network.target
   
   [Service]
   Type=simple
   User=<your-user>
   WorkingDirectory=/opt/douban_zlib
   ExecStart=/opt/douban_zlib/venv/bin/python /opt/douban_zlib/main.py
   Restart=on-failure
   RestartSec=5
   
   [Install]
   WantedBy=multi-user.target
   ```

   å¯ç”¨æœåŠ¡ï¼š

   ```bash
   sudo systemctl enable douban-zlib.service
   sudo systemctl start douban-zlib.service
   ```

   **Windows**:

   åˆ›å»ºè®¡åˆ’ä»»åŠ¡ï¼Œè®¾ç½®å¼€æœºè‡ªå¯åŠ¨ã€‚

4. **æ—¥å¿—è½®è½¬**

   åˆ›å»º `/etc/logrotate.d/douban-zlib` æ–‡ä»¶ï¼š

   ```
   /opt/douban_zlib/logs/*.log {
       daily
       missingok
       rotate 7
       compress
       delaycompress
       notifempty
       create 0640 <your-user> <your-group>
   }
   ```

### 3. ç›‘æ§ä¸ç»´æŠ¤

1. **æ£€æŸ¥ç³»ç»ŸçŠ¶æ€**

   ```bash
   # æŸ¥çœ‹æœåŠ¡çŠ¶æ€
   sudo systemctl status douban-zlib.service
   
   # æŸ¥çœ‹æ—¥å¿—
   tail -f /opt/douban_zlib/logs/app.log
   ```

2. **æ‰‹åŠ¨è§¦å‘åŒæ­¥**

   ```bash
   # ç«‹å³æ‰§è¡ŒåŒæ­¥ä»»åŠ¡
   cd /opt/douban_zlib
   source venv/bin/activate
   python main.py --run-now
   ```

3. **æ•°æ®åº“å¤‡ä»½**

   ```bash
   # å¤‡ä»½ SQLite æ•°æ®åº“
   cp /opt/douban_zlib/data/douban_books.db /backup/douban_books_$(date +%Y%m%d).db
   ```

4. **æ›´æ–°ç³»ç»Ÿ**

   ```bash
   # æ›´æ–°ä»£ç 
   cd /opt/douban_zlib
   git pull
   
   # æ›´æ–°ä¾èµ–
   source venv/bin/activate
   pip install -r requirements.txt
   
   # é‡å¯æœåŠ¡
   sudo systemctl restart douban-zlib.service
   ```

## å¸¸è§é—®é¢˜è§£å†³

### 1. è±†ç“£çˆ¬è™«é—®é¢˜

**é—®é¢˜**ï¼šçˆ¬è™«æ— æ³•è·å–æ•°æ®æˆ–ç™»å½•å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥ Cookie æ˜¯å¦æœ‰æ•ˆï¼Œå¯èƒ½éœ€è¦é‡æ–°è·å–
- æ£€æŸ¥ç½‘ç«™ç»“æ„æ˜¯å¦å˜åŒ–ï¼Œå¯èƒ½éœ€è¦æ›´æ–°é€‰æ‹©å™¨
- æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…è¢«åçˆ¬è™«æœºåˆ¶æ£€æµ‹

### 2. Z-Library ä¸‹è½½é—®é¢˜

**é—®é¢˜**ï¼šæ— æ³•ä» Z-Library ä¸‹è½½ä¹¦ç±

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥è´¦å·æ˜¯å¦æœ‰æ•ˆï¼Œå¯èƒ½éœ€è¦é‡æ–°ç™»å½•
- æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ä¸‹è½½é™åˆ¶ï¼Œå¯èƒ½éœ€è¦ç­‰å¾…æˆ–ä½¿ç”¨å…¶ä»–è´¦å·
- å°è¯•ä½¿ç”¨ä»£ç†æœåŠ¡å™¨ï¼Œé¿å… IP è¢«å°é”

### 3. Calibre è¿æ¥é—®é¢˜

**é—®é¢˜**ï¼šæ— æ³•è¿æ¥åˆ° Calibre Content Server

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ç¡®è®¤ Calibre Content Server æ˜¯å¦æ­£åœ¨è¿è¡Œ
- æ£€æŸ¥æœåŠ¡å™¨åœ°å€ã€ç”¨æˆ·åå’Œå¯†ç æ˜¯å¦æ­£ç¡®
- æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™è®¾ç½®

### 4. æ•°æ®åº“é—®é¢˜

**é—®é¢˜**ï¼šæ•°æ®åº“æ“ä½œå¤±è´¥æˆ–æ€§èƒ½ä¸‹é™

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥æ•°æ®åº“è¿æ¥é…ç½®
- ä¼˜åŒ–ç´¢å¼•å’ŒæŸ¥è¯¢
- å®šæœŸæ¸…ç†å†å²æ•°æ®

### 5. è°ƒåº¦é—®é¢˜

**é—®é¢˜**ï¼šå®šæ—¶ä»»åŠ¡æœªæ‰§è¡Œ

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥ç³»ç»Ÿæ—¶é—´æ˜¯å¦æ­£ç¡®
- ç¡®è®¤è°ƒåº¦å™¨æ˜¯å¦æ­£å¸¸è¿è¡Œ
- æ£€æŸ¥æ—¥å¿—ä¸­æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯

## ç»“è¯­

æœ¬å¼€å‘æŒ‡å—æä¾›äº†ã€Œè±†ç“£ä¹¦å•åŒæ­¥ä¸ Calibre é›†æˆè‡ªåŠ¨åŒ–ã€é¡¹ç›®çš„è¯¦ç»†å®æ–½æŒ‡å¯¼ã€‚é€šè¿‡éµå¾ªæœ¬æŒ‡å—ï¼Œå¼€å‘äººå‘˜å¯ä»¥é«˜æ•ˆåœ°å®ç°å„ä¸ªæ¨¡å—ï¼Œå¹¶å°†å®ƒä»¬é›†æˆä¸ºä¸€ä¸ªå®Œæ•´çš„ç³»ç»Ÿã€‚

åœ¨å¼€å‘è¿‡ç¨‹ä¸­ï¼Œè¯·æ³¨æ„éµå¾ªä»£ç è§„èŒƒï¼Œç¼–å†™å……åˆ†çš„æµ‹è¯•ï¼Œå¹¶ä¿æŒè‰¯å¥½çš„æ–‡æ¡£ä¹ æƒ¯ã€‚å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·å‚è€ƒé¡¹ç›® README æˆ–è”ç³»é¡¹ç›®ç»´æŠ¤è€…ã€‚