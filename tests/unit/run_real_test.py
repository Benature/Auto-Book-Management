#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¿è¡ŒçœŸå®ç½‘ç»œæµ‹è¯•çš„è„šæœ¬

ä½¿ç”¨ç¤ºä¾‹:
    python tests/unit/run_real_test.py
    python tests/unit/run_real_test.py --book-id 26912767
"""

import argparse
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
FILE_DIR = Path(__file__).resolve().parent
sys.path.insert(0, str(FILE_DIR.parent.parent))

from config.config_manager import ConfigManager
from scrapers.douban_scraper import DoubanScraper


def run_real_test(book_id=None):
    """è¿è¡ŒçœŸå®ç½‘ç»œæµ‹è¯•"""
    print("å¼€å§‹è¿è¡ŒçœŸå®ç½‘ç»œæµ‹è¯•...")
    
    try:
        # åŠ è½½é…ç½®
        config_manager = ConfigManager(Path(__file__).parent.parent.parent / 'config.yaml')
        douban_config = config_manager.get_douban_config()
        
        # æ£€æŸ¥cookieé…ç½®
        cookie = douban_config.get('cookie', '')
        if not cookie:
            print("âŒ é”™è¯¯: éœ€è¦åœ¨config.yamlä¸­é…ç½®æœ‰æ•ˆçš„è±†ç“£cookie")
            return False
            
        print("âœ… æ£€æµ‹åˆ°cookieé…ç½®")
        
        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        system_config = config_manager.get_system_config()
        user_agent = system_config.get('user_agent')
        max_pages = douban_config.get('max_pages', 1)
        
        scraper = DoubanScraper(
            cookie=cookie,
            user_agent=user_agent,
            max_pages=max_pages
        )
        
        print("ğŸ”„ æ­£åœ¨æµ‹è¯•è·å–æƒ³è¯»ä¹¦å•...")
        
        # æµ‹è¯•è·å–æƒ³è¯»ä¹¦å•
        wish_list = scraper.get_wish_list()
        print(f"âœ… æˆåŠŸè·å– {len(wish_list)} æœ¬æƒ³è¯»ä¹¦ç±")
        
        if wish_list:
            print("\nğŸ“š ä¹¦å•é¢„è§ˆ:")
            for i, book in enumerate(wish_list[:3], 1):
                print(f"  {i}. {book.get('title', 'æœªçŸ¥æ ‡é¢˜')} - {book.get('author', 'æœªçŸ¥ä½œè€…')}")
            
            # å¦‚æœæœ‰æŒ‡å®šä¹¦ç±IDï¼Œæµ‹è¯•è·å–è¯¦æƒ…
            if book_id:
                print(f"\nğŸ”„ æ­£åœ¨æµ‹è¯•è·å–ä¹¦ç± {book_id} çš„è¯¦æƒ…...")
                book_detail = scraper.get_book_detail(book_id)
                if book_detail:
                    print("âœ… æˆåŠŸè·å–ä¹¦ç±è¯¦æƒ…:")
                    print(f"   æ ‡é¢˜: {book_detail.get('title', 'æœªçŸ¥')}")
                    print(f"   ä½œè€…: {book_detail.get('author', 'æœªçŸ¥')}")
                    print(f"   è¯„åˆ†: {book_detail.get('rating', 'æœªçŸ¥')}")
                    print(f"   ISBN: {book_detail.get('isbn', 'æœªçŸ¥')}")
                else:
                    print("âŒ æ— æ³•è·å–ä¹¦ç±è¯¦æƒ…")
        
        print("\nğŸ‰ çœŸå®ç½‘ç»œæµ‹è¯•å®Œæˆ!")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='è¿è¡Œè±†ç“£çˆ¬è™«çœŸå®ç½‘ç»œæµ‹è¯•')
    parser.add_argument('--book-id', 
                       default=None, 
                       help='æŒ‡å®šæµ‹è¯•çš„ä¹¦ç±ID (ä¾‹å¦‚: 26912767)')
    
    args = parser.parse_args()
    
    success = run_real_test(args.book_id)
    sys.exit(0 if success else 1)